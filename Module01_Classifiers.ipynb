{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CÃ³pia de Module01_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbsobral/ml-fies/blob/main/Module01_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSSIbHD3ogH6"
      },
      "source": [
        "## Module 01 - Models\n",
        "\n",
        "In this module, we perform the following steps:\n",
        "\n",
        "1. Load the data from Mod_00 and create sets and targets for train and test datasets;\n",
        "2. Standardize and encode observations;\n",
        "3. Run preliminary model;\n",
        "4. Provide performance measures and visualization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNfxqJE4km2n"
      },
      "source": [
        "### 1 - Load Data\n",
        "\n",
        "Here, we import the training and testing sets created in Module00_Data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1T2rReQkmI5",
        "outputId": "6447c43b-81ba-46c0-b425-a1d40ef2ec65"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_train = \"https://drive.google.com/file/d/1IP7jyXkLgD_Ouy5cL6fJk4VUA5qRB2PK/view?usp=sharing\"\n",
        "path_train = \"https://drive.google.com/uc?export=download&id=\"+url_train.split(\"/\")[-2]\n",
        "train = pd.read_csv(path_train)\n",
        "train.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351001, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaJOQTurG_Li",
        "outputId": "0b0b22ef-32e7-438e-b855-5a3a5e526dad"
      },
      "source": [
        "url_test = \"https://drive.google.com/file/d/1v4FqKwt7NzG5RM6d9f1y7CLIdKq69jSS/view?usp=sharing\"\n",
        "path_test = \"https://drive.google.com/uc?export=download&id=\"+url_test.split(\"/\")[-2]\n",
        "test = pd.read_csv(path_test)\n",
        "test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87751, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNgDRsr2rMz"
      },
      "source": [
        "train_set = train.drop(\"default\", axis=1) # drop targets for training set\n",
        "train_target = train[\"default\"].copy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJhx2yRNHRoy"
      },
      "source": [
        "test_set = test.drop(\"default\", axis=1) # drop targets for test set\n",
        "test_target = test[\"default\"].copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIJ6MzxrogIO"
      },
      "source": [
        "### 2 - Pipeline\n",
        "\n",
        "The pipeline contains functions that will be used to transform the dataset. For the numeric attributes, the stardardization is performed by the StandardScaler. For ordinal attributes, variables are encoded by the OrdinalEncoder, and for categorical, theOneHotEncoder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKb_CdHogIR"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"std_scaler\", StandardScaler()),\n",
        "    ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGJn2aCfAuXj"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ord_pipeline = Pipeline([\n",
        "        (\"ord_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord_encoder\", OrdinalEncoder()),\n",
        "    ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gaCsGRFogIR"
      },
      "source": [
        "ord_attribs = [\"igc\",\"date_contract\"] # 2 attributes\n",
        "\n",
        "num_attribs = [\"family_income\",   #17\n",
        "               \"personal_income\",\n",
        "               \"high_school_endyear\",\n",
        "               \"n_sem_course\",\n",
        "               \"n_completed_sem\",\n",
        "               \"sem_funded\",\n",
        "               \"fam_size\",\n",
        "               \"income_pc\",\n",
        "               \"tuition_current\",\n",
        "               \"inc_prop\",\n",
        "               \"perc_requested\",\n",
        "               \"loan_value_sem\",\n",
        "               \"student_resource\",\n",
        "               \"loan_value\",\n",
        "               \"loan_limit\",\n",
        "               \"total_debt\",\n",
        "               \"age\"]\n",
        "  \n",
        "\n",
        "cat_attribs = [\"semester_enroll\",  #9\n",
        "               \"gender\",\n",
        "               \"occupation\", \n",
        "               \"marital_status\",\n",
        "               \"ethnicity\", \n",
        "               \"public_hs\", \n",
        "               \"state_course\", \n",
        "               \"degree\", \n",
        "               \"contract_phase\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgFC9XOHAuXk"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "        (\"ord\", ord_pipeline, ord_attribs)\n",
        "        ])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGEokMJdAuXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad38110-8869-41d6-8f6d-35901a783f5f"
      },
      "source": [
        "train_prepared = full_pipeline.fit_transform(train_set)\n",
        "train_prepared[:1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x94 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 28 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtlBac6BXY4k",
        "outputId": "c53a5d05-2783-4988-fa06-f8c6a43d9c48"
      },
      "source": [
        "test_prepared = full_pipeline.fit_transform(test_set)\n",
        "test_prepared[:1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x94 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 28 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CASdeLRZ_ZZ"
      },
      "source": [
        "### 3 - Classifiers\n",
        "\n",
        "For the initial runs, we employ 5 methods: logistic regression, decision tree, random forest, linear support vector classification (SVC), and artificial neural networks (ANN). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIeJWYMpHFQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3226b7-a43f-4248-cbf1-a5d7be9dfdac"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "logr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logr.fit(train_prepared, train_target)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfEBJV5jZS6"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc = dtc.fit(train_prepared, train_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-99RFgmhHsem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b19878-40c8-41ee-eb55-573e25f1001e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(train_prepared, train_target)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coOFv5bZE4yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550cd64c-a462-4dca-c4b9-8eb148fbf695"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm = LinearSVC(C=1, loss=\"hinge\", max_iter=1000)\n",
        "svm.fit(train_prepared, train_target)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
              "          penalty='l2', random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3SB0LW4E-2m"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "ann = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "ann.fit(train_prepared, train_target.values.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMo644RChXV"
      },
      "source": [
        "### 4 - Performance Evaluation\n",
        "\n",
        "To asses the preliminary results of the classifiers on the test set, we use the AUC. Using cross-validation for the training set, the best result was achieved with the ANN -- AUC of XX%. The best performing models on the test set, in line with the cross-validation scores, were XX and XX. AUC of XX% and XX%, respectively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45tFlNTkeLUL"
      },
      "source": [
        "#### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4zuSJv1eVli"
      },
      "source": [
        "cross_logr = (cross_val_score(logr, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()\n",
        "cross_dtc = (cross_val_score(dtc, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()\n",
        "cross_rf = (cross_val_score(rf, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()\n",
        "cross_svm = (cross_val_score(svm, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()\n",
        "cross_ann = (cross_val_score(ann, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlBL4Wf_4Kmn"
      },
      "source": [
        "# List with AUC scores for training set\n",
        "cross_list = [cross_logr, cross_dtc, cross_rf, cross_svm, cross_ann]\n",
        "\n",
        "# Dataframe \n",
        "cross_df = pd.DataFrame({\"AUC\": cross_list})\n",
        "cross_df.sort_values(by = \"AUC\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFmYN3lePKQ"
      },
      "source": [
        "#### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lUr8ie6AQW2"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Predict probabilities for test set\n",
        "pred_logr = logr.predict_proba(test_prepared)\n",
        "pred_dtc = dtc.predict_proba(test_prepared)\n",
        "pred_rf = rf.predict_proba(test_prepared)\n",
        "pred_svm = svm.predict_proba(test_prepared)\n",
        "pred_ann = ann.predict_proba(test_prepared)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwnJNjFb3atd"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# AUC score\n",
        "auc_logr = roc_auc_score(test_target, pred_logr[:,1])\n",
        "auc_dtc = roc_auc_score(test_target, pred_dtc[:,1])\n",
        "auc_rf = roc_auc_score(test_target, pred_rf[:,1])\n",
        "auc_svm = roc_auc_score(test_target, pred_svm[:,1])\n",
        "auc_ann = roc_auc_score(test_target, pred_ann[:,1])\n",
        "\n",
        "# List with AUC scores\n",
        "auc_list = [auc_logr, auc_dtc, auc_rf, auc_svm, auc_ann]\n",
        "\n",
        "# Dataframe \n",
        "auc_df= pd.DataFrame({\"AUC\": auc_list})\n",
        "auc_df.sort_values(by = \"AUC\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlPPx7NHBJ4C"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr_logr, tpr_logr, thresh_logr = roc_curve(test_target, pred_logr[:,1], pos_label=1)\n",
        "fpr_dtc, tpr_dtc, thresh_dtc = roc_curve(test_target, pred_dtc[:,1], pos_label=1)\n",
        "fpr_rf, tpr_rf, thresh_rf = roc_curve(test_target, pred_rf[:,1], pos_label=1)\n",
        "fpr_svm, tpr_svm, thresh_svm = roc_curve(test_target, pred_svm[:,1], pos_label=1)\n",
        "fpr_ann, tpr_ann, thresh_ann = roc_curve(test_target, pred_ann[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(test_target))]\n",
        "p_fpr, p_tpr, _ = roc_curve(test_target, random_probs, pos_label=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COwC7FNZBIyr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr_logr, tpr_logr, linestyle=\"--\",color=\"purple\", label=\"LR\")\n",
        "plt.plot(fpr_dtc, tpr_dtc, linestyle=\"--\",color=\"green\", label=\"DT\")\n",
        "plt.plot(fpr_rf, tpr_rf, linestyle=\"--\",color=\"blue\", label=\"RF\")\n",
        "plt.plot(fpr_rf, tpr_rf, linestyle=\"--\",color=\"orange\", label=\"SVM\")\n",
        "plt.plot(fpr_svm, tpr_svm, linestyle=\"--\",color=\"red\", label=\"ANN\")\n",
        "plt.plot(fpr_ann, tpr_ann, linestyle=\"--\", color=\"black\")\n",
        "\n",
        "# title\n",
        "plt.title(\"ROC Curve\")\n",
        "# x label\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "# y label\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig(\"ROC\", dpi = 300)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5RxIGbkI-y1"
      },
      "source": [
        "### X - Feature Importance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_gp3UztJiOU"
      },
      "source": [
        "feat_names = list(train_set.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsidQMRWJCQn"
      },
      "source": [
        "rf.feature_importances_\n",
        "plt.barh(feat_names, rf.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDw7K6IYI6Vd"
      },
      "source": [
        "### X - Save Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABIS4YF3_K9M"
      },
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(logr, logr.sav)\n",
        "joblib.dump(dtc, dtc.sav)\n",
        "joblib.dump(svm, svm.sav)\n",
        "joblib.dump(ann, ann.sav)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSsF12yFvO9"
      },
      "source": [
        "import joblib\n",
        "\n",
        "logr = joblib.load(logr.sav)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}