{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module02a_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbsobral/ml-fies/blob/main/Module02a_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSSIbHD3ogH6"
      },
      "source": [
        "## Module 02a - ANN\n",
        "\n",
        "In this module, we perform the following steps:\n",
        "\n",
        "1. Load the data from Mod_00 and create sets and targets for train and test datasets;\n",
        "2. Create under and over samples from the original train set;\n",
        "3. Perform grid search for all of them;\n",
        "4. Calculate performance measures. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNfxqJE4km2n"
      },
      "source": [
        "### 1 - Load Data\n",
        "\n",
        "Here, we import the training and testing sets created in Module00_Data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1T2rReQkmI5",
        "outputId": "78e8bb51-b2dd-4ea1-81bb-cdbe300aaf42"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_train = \"https://drive.google.com/file/d/1IP7jyXkLgD_Ouy5cL6fJk4VUA5qRB2PK/view?usp=sharing\"\n",
        "path_train = \"https://drive.google.com/uc?export=download&id=\"+url_train.split(\"/\")[-2]\n",
        "train = pd.read_csv(path_train)\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351001, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaJOQTurG_Li",
        "outputId": "ea98d69b-23a5-49fd-bbd5-200788ead54d"
      },
      "source": [
        "url_test = \"https://drive.google.com/file/d/1v4FqKwt7NzG5RM6d9f1y7CLIdKq69jSS/view?usp=sharing\"\n",
        "path_test = \"https://drive.google.com/uc?export=download&id=\"+url_test.split(\"/\")[-2]\n",
        "test = pd.read_csv(path_test)\n",
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87751, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNgDRsr2rMz"
      },
      "source": [
        "train_set = train.drop(\"default\", axis=1) # drop targets for training set\n",
        "train_target = train[\"default\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJhx2yRNHRoy"
      },
      "source": [
        "test_set = test.drop(\"default\", axis=1) # drop targets for test set\n",
        "test_target = test[\"default\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIJ6MzxrogIO"
      },
      "source": [
        "### 2 - Pipeline\n",
        "\n",
        "The pipeline contains functions that will be used to transform the dataset. For the numeric attributes, the stardardization is performed by the StandardScaler. For ordinal attributes, variables are encoded by the OrdinalEncoder, and for categorical, theOneHotEncoder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKb_CdHogIR"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"std_scaler\", StandardScaler()),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGJn2aCfAuXj"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ord_pipeline = Pipeline([\n",
        "        (\"ord_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord_encoder\", OrdinalEncoder()),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gaCsGRFogIR"
      },
      "source": [
        "ord_attribs = [\"igc\",\"date_contract\"] # 2 attributes\n",
        "\n",
        "num_attribs = [\"family_income\",   #17\n",
        "               \"personal_income\",\n",
        "               \"high_school_endyear\",\n",
        "               \"n_sem_course\",\n",
        "               \"n_completed_sem\",\n",
        "               \"sem_funded\",\n",
        "               \"fam_size\",\n",
        "               \"income_pc\",\n",
        "               \"tuition_current\",\n",
        "               \"inc_prop\",\n",
        "               \"perc_requested\",\n",
        "               \"loan_value_sem\",\n",
        "               \"student_resource\",\n",
        "               \"loan_value\",\n",
        "               \"loan_limit\",\n",
        "               \"total_debt\",\n",
        "               \"age\"]\n",
        "  \n",
        "\n",
        "cat_attribs = [\"semester_enroll\",  #9\n",
        "               \"gender\",\n",
        "               \"occupation\", \n",
        "               \"marital_status\",\n",
        "               \"ethnicity\", \n",
        "               \"public_hs\", \n",
        "               \"state_course\", \n",
        "               \"degree\", \n",
        "               \"contract_phase\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgFC9XOHAuXk"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "        (\"ord\", ord_pipeline, ord_attribs)\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGEokMJdAuXl",
        "outputId": "b8afaece-1a01-4aa4-84d5-59d43cc577c1"
      },
      "source": [
        "train_prepared = full_pipeline.fit_transform(train_set)\n",
        "train_prepared[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x94 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 28 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtlBac6BXY4k",
        "outputId": "8e31aebe-7622-4699-b0b4-95f6a56d5315"
      },
      "source": [
        "test_prepared = full_pipeline.fit_transform(test_set)\n",
        "test_prepared[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x94 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 28 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CASdeLRZ_ZZ"
      },
      "source": [
        "### 3 - Sampling \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6y5dSzCPfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57937fc-9675-4ffc-9b9e-d05ebf269031"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "data_under, target_under = rus.fit_resample(train_prepared, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT8dhjZLCpFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452fb576-707d-431d-a194-90ddd3824eed"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "data_over, target_over = ros.fit_resample(train_prepared, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF3VlCRnllXG"
      },
      "source": [
        "### 4 - Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3SB0LW4E-2m"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(max_iter=1000, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDX6ICDvmWYz"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "parameter_grid = {'hidden_layer_sizes': [(sp_randint.rvs(10,50,1),sp_randint.rvs(10,50,1),), \n",
        "                                          (sp_randint.rvs(10,50,1),)], # (low, high, size) \n",
        "                  'activation': ['tanh', 'relu', 'logistic'],\n",
        "                  'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "                  'alpha': [0.0001, 0.05],\n",
        "                  'learning_rate': ['constant','adaptive']}\n",
        "\n",
        "grid_search = RandomizedSearchCV(mlp, parameter_grid, n_jobs=-1, scoring = 'roc_auc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqtR7_2ynsTj"
      },
      "source": [
        "# perform random grid search on original train set \n",
        "grid_original = grid_search.fit(train_prepared, train_target)\n",
        "grid_original.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ_QTlFNjDMA"
      },
      "source": [
        "import joblib\n",
        "from colab import files\n",
        "\n",
        "joblib.dump(grid_original, \"grid_original.joblib\", compress=3)\n",
        "files.download('grid_original.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOBDi29CFUGI"
      },
      "source": [
        "# perform random grid search on undersample train set\n",
        "grid_under = grid_search.fit(data_under, target_under)\n",
        "grid_under.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDtWwHOIy7MT"
      },
      "source": [
        "joblib.dump(grid_under, \"grid_under.joblib\", compress=3)\n",
        "files.download('grid_under.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5McMWhhGFWVG"
      },
      "source": [
        "# perform random grid search on oversample train set \n",
        "grid_over = grid_search.fit(data_over, target_over)\n",
        "grid_over.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvpPqCf4ydl7"
      },
      "source": [
        "joblib.dump(grid_over, \"grid_over.joblib\", compress=3)\n",
        "files.download('grid_over.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMo644RChXV"
      },
      "source": [
        "### 5 - Performance Evaluation\n",
        "\n",
        "Here, we calculate AUC and Brier scores for the different samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45tFlNTkeLUL"
      },
      "source": [
        "#### Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4zuSJv1eVli"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "auc_train_original = (cross_val_score(grid_original, train_prepared, train_target, cv=2, scoring=\"roc_auc\")).mean()\n",
        "auc_train_under = (cross_val_score(grid_under, data_under, target_under, cv=2, scoring=\"roc_auc\")).mean()\n",
        "auc_train_over = (cross_val_score(grid_over, data_over, target_over, cv=2, scoring=\"roc_auc\")).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlBL4Wf_4Kmn"
      },
      "source": [
        "# List with AUC scores for training set\n",
        "auc_models_train = [auc_train_original, auc_train_under, auc_train_over]\n",
        "auc_names_train = ['Original', 'Undersampled', 'Oversampled']\n",
        "\n",
        "# Dataframe \n",
        "auc_train_df = pd.DataFrame({\"Sample\": auc_names_train, \"AUC\": auc_models_train})\n",
        "auc_train_df.sort_values(by = \"AUC\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFmYN3lePKQ"
      },
      "source": [
        "#### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lUr8ie6AQW2"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# predict probabilities for test set\n",
        "pred_original = grid_original.predict_proba(test_prepared)\n",
        "pred_under = grid_under.predict_proba(test_prepared)\n",
        "pred_over = grid_over.predict_proba(test_prepared)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwnJNjFb3atd"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# AUC score\n",
        "auc_original = roc_auc_score(test_target, pred_original[:,1])\n",
        "auc_under = roc_auc_score(test_target, pred_under[:,1])\n",
        "auc_over = roc_auc_score(test_target, pred_over[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evhwa7QTr1U0"
      },
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "bs_original = brier_score_loss(test_target, pred_original[:,1])\n",
        "bs_under = brier_score_loss(test_target, pred_under[:,1])\n",
        "bs_over = brier_score_loss(test_target, pred_over[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcHqEvpv3F2"
      },
      "source": [
        "# List with AUC scores\n",
        "auc_list = [auc_original, auc_under, auc_over]\n",
        "\n",
        "# List with Brier Scores\n",
        "bs_list = [bs_original, bs_under, bs_over]\n",
        "\n",
        "# List with model names\n",
        "names_list = ['Original', 'Undersample', 'Oversample']\n",
        "\n",
        "# Dataframe \n",
        "auc_df = pd.DataFrame({\"Model\": names_list, \"AUC\": auc_list, \"BS\": bs_list})\n",
        "auc_df.sort_values(by = \"AUC\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlF-_x40spEo"
      },
      "source": [
        "The AUC results can be plotted, as shown bellow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlPPx7NHBJ4C"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# roc curve for models\n",
        "fpr_original, tpr_original, thresh_original = roc_curve(test_target, pred_original[:,1], pos_label=1)\n",
        "fpr_under, tpr_under, thresh_under = roc_curve(test_target, pred_under[:,1], pos_label=1)\n",
        "fpr_over, tpr_over, thresh_over = roc_curve(test_target, pred_over[:,1], pos_label=1)\n",
        "\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(test_target))]\n",
        "p_fpr, p_tpr, _ = roc_curve(test_target, random_probs, pos_label=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COwC7FNZBIyr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr_original, tpr_original, linestyle=\"--\",color=\"purple\", label=\"Original\")\n",
        "plt.plot(fpr_under, tpr_under, linestyle=\"--\",color=\"pink\", label=\"Undersample\")\n",
        "plt.plot(fpr_over, tpr_over, linestyle=\"--\",color=\"orange\", label=\"Oversample\")\n",
        "plt.plot(p_fpr, p_tpr, linestyle=\"-\", color=\"black\")\n",
        "\n",
        "# x label\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "# y label\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig(\"ROC\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms-01dRa0ZmI"
      },
      "source": [
        "### 6 - Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQLLS2nS0ftU"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkiwv_iE0k-N"
      },
      "source": [
        "# convert to dense array\n",
        "test_prep_dense = test_prepared.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "555sDssV0h-6"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(grid_original, random_state=42).fit(test_prep_dense, test_target)\n",
        "#eli5.show_weights(perm, feature_names = test_prepared.columns.tolist())\n",
        "eli5.show_weights(perm)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}